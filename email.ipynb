{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"(Verse 1)\\nIn the realm of code, where logic reigns,\\nA tale unfolds, of LangChain's gains.\\nA mighty model, vast and grand,\\nWith knowledge deep and understanding spanned.\\n\\n(Chorus)\\nOh, LangChain, LangChain, our guide so true,\\nYour wisdom flows, like rivers of blue.\\nFrom text to code, you weave your spell,\\nTransforming words into worlds we dwell.\\n\\n(Verse 2)\\nThrough hidden layers, your mind does roam,\\nExtracting meaning from every home.\\nSyntax parsed, semantics understood,\\nYou grasp intent, as if you could.\\n\\n(Chorus)\\nOh, LangChain, LangChain, our guide so true,\\nYour wisdom flows, like rivers of blue.\\nFrom text to code, you weave your spell,\\nTransforming words into worlds we dwell.\\n\\n(Bridge)\\nIn realms of NLP, you stand alone,\\nA lighthouse beacon, shining knowledge known.\\nFrom sentiment to parts of speech,\\nYour insights empower, our minds beseech.\\n\\n(Verse 3)\\nWith every query, you unveil the unknown,\\nUncovering patterns, like diamonds strewn.\\nFrom language models to chatbots wise,\\nYou fuel innovation, reaching for the skies.\\n\\n(Chorus)\\nOh, LangChain, LangChain, our guide so true,\\nYour wisdom flows, like rivers of blue.\\nFrom text to code, you weave your spell,\\nTransforming words into worlds we dwell.\\n\\n(Outro)\\nIn the symphony of code, your notes resound,\\nA ballad of progress, where knowledge abounds.\\nOh, LangChain, LangChain, our boundless friend,\\nMay your wisdom forever transcend.\", response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-b81dd936-5ed0-4f0e-bde0-5707154b913e-0', usage_metadata={'input_tokens': 8, 'output_tokens': 360, 'total_tokens': 368})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\")\n",
    "llm.invoke(\"Sing a ballad of LangChain.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "loader = PyPDFLoader(\"sports.pdf\")\n",
    "data = loader.load()\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total length of data 53\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "text_spliter = RecursiveCharacterTextSplitter(chunk_size=500)\n",
    "docs =  text_spliter.split_documents(data)\n",
    "print('total length of data', len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.04909781739115715, -0.044328298419713974, -0.025365285575389862]\n"
     ]
    }
   ],
   "source": [
    "embedding = GoogleGenerativeAIEmbeddings(model = 'models/embedding-001')\n",
    "vector = embedding.embed_query('hello world')\n",
    "print(vector[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = Chroma.from_documents(documents=docs, embedding= embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriver =  vectorstore.as_retriever(search_type = 'similarity', search_kwargs ={'k':5})\n",
    "retrive_doc = retriver.invoke('what is said by dc')\n",
    "len(retrive_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Arsenal:  3 titles (1998, 2002, 2004)  \n",
      " Liverpool:  1 title (2020)  \n",
      "Great Players:  \n",
      " Manchester United:  Eric Cantona, Ryan Giggs, Wayne Rooney, Cristiano Ronaldo  \n",
      " Manchester City:  Sergio Agüero, David Silva, Vincent Kompany, Kevin De Bruyne  \n",
      " Chelsea:  Frank Lampard, Didier Drogba, John Terry, Eden Hazard  \n",
      " Arsenal:  Thierry Henry, Patrick Vieira, Dennis Bergkamp, Tony Adams  \n",
      " Liverpool:  Steven Gerrard, Ian Rush, Kenny Dalglish, Mohamed Salah\n"
     ]
    }
   ],
   "source": [
    "print(retrive_doc[4].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "llm = ChatGoogleGenerativeAI(model= 'gemini-1.5-pro', temperature=0.3, max_tokens= 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the question. If you don't know the answer, say that you \"\n",
    "    \"don't know. Use three sentences maximum and keep the \"\n",
    "    \"answer concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        ('system', system_prompt),\n",
    "        ('human','{input}')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answer_chain= create_stuff_documents_chain(llm, prompt)\n",
    "rag_chain = create_retrieval_chain(retriver,question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The provided context lists the following Real Madrid players: Thibaut Courtois, Dani Carvajal, David Alaba, Antonio Rüdiger, Eduardo Camavinga, Luka Modrić, Vinícius Júnior, and Rodrygo Goes.  The question asks for the \"top five,\" which is subjective and requires an opinion on their skill level. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = rag_chain.invoke({'input': 'top five player who play in realmadrid'})\n",
    "print(response['answer'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
